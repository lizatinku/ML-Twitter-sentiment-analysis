{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfiyTS_hc7Ue",
        "outputId": "368679e6-6a3f-4f2c-d014-23abb198747c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.5)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "ZP3IfK-Wov_l"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d kazanova/sentiment140"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81Rx9ey9psLb",
        "outputId": "e2989824-a82c-473c-8cbd-bcc81f67c9b9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/kazanova/sentiment140\n",
            "License(s): other\n",
            "sentiment140.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "dataset = '/content/sentiment140.zip'\n",
        "\n",
        "with ZipFile(dataset, 'r') as zip:\n",
        "    zip.extractall()\n",
        "    print('The dataset is extracted')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWZnx0DcqHGY",
        "outputId": "16879689-ff60-4e35-98c2-2de0dfe3cec8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dataset is extracted\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "zutA70Kpq5gG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "# Initialize stopwords and stemmer\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stemmer = PorterStemmer()"
      ],
      "metadata": {
        "id": "C6bm3KSauzRj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "twitter_data = pd.read_csv('/content/training.1600000.processed.noemoticon.csv', encoding='ISO-8859-1')\n",
        "\n",
        "print(twitter_data.shape)\n",
        "print(twitter_data.head())\n",
        "\n",
        "# Assigning column names\n",
        "column_names = ['target', 'id', 'date', 'flag', 'user', 'text']\n",
        "twitter_data.columns = column_names\n",
        "\n",
        "print(twitter_data.shape)\n",
        "print(twitter_data.head())"
      ],
      "metadata": {
        "id": "03-71pj2wwCJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9260ef83-44d5-47bb-ee44-f4e17f3a82ec"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1599999, 6)\n",
            "   0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY _TheSpecialOne_  \\\n",
            "0  0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   scotthamilton   \n",
            "1  0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY        mattycus   \n",
            "2  0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY         ElleCTF   \n",
            "3  0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          Karoli   \n",
            "4  0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY        joy_wolf   \n",
            "\n",
            "  @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D  \n",
            "0  is upset that he can't update his Facebook by ...                                                                   \n",
            "1  @Kenichan I dived many times for the ball. Man...                                                                   \n",
            "2    my whole body feels itchy and like its on fire                                                                    \n",
            "3  @nationwideclass no, it's not behaving at all....                                                                   \n",
            "4                      @Kwesidei not the whole crew                                                                    \n",
            "(1599999, 6)\n",
            "   target          id                          date      flag           user  \\\n",
            "0       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY  scotthamilton   \n",
            "1       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY       mattycus   \n",
            "2       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY        ElleCTF   \n",
            "3       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY         Karoli   \n",
            "4       0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY       joy_wolf   \n",
            "\n",
            "                                                text  \n",
            "0  is upset that he can't update his Facebook by ...  \n",
            "1  @Kenichan I dived many times for the ball. Man...  \n",
            "2    my whole body feels itchy and like its on fire   \n",
            "3  @nationwideclass no, it's not behaving at all....  \n",
            "4                      @Kwesidei not the whole crew   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for missing values\n",
        "print(twitter_data.isnull().sum())\n",
        "\n",
        "# Checking the distribution of target values\n",
        "print(twitter_data['target'].value_counts())\n",
        "\n",
        "# Replace=ing sentiment label 4 with 1 for positive sentiment\n",
        "twitter_data.replace({'target': {4: 1}}, inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAbwvkn-yYoj",
        "outputId": "a8ab6d18-696a-4c60-b466-4476eaa31e00"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target    0\n",
            "id        0\n",
            "date      0\n",
            "flag      0\n",
            "user      0\n",
            "text      0\n",
            "dtype: int64\n",
            "target\n",
            "4    800000\n",
            "0    799999\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "    text = re.sub(r'@\\w+', '', text)\n",
        "    text = re.sub(r'#\\w+', '', text)\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    text = text.lower()\n",
        "    return text\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = clean_text(text)\n",
        "    words = text.split()\n",
        "    words = [stemmer.stem(word) for word in words if word not in stop_words]\n",
        "    return ' '.join(words)"
      ],
      "metadata": {
        "id": "HeR70vjQI56J"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "twitter_data['processed_text'] = twitter_data['text'].apply(preprocess_text)"
      ],
      "metadata": {
        "id": "0VLBk2IbJBX1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(twitter_data['processed_text'])\n",
        "\n",
        "y = twitter_data['target']"
      ],
      "metadata": {
        "id": "f9YV6bliNTwA"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f'Training data shape: {X_train.shape}')\n",
        "print(f'Test data shape: {X_test.shape}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9st9Yf_BNJYd",
        "outputId": "bb086a49-0003-4874-8ced-427cfb47451f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: (1279999, 388479)\n",
            "Test data shape: (320000, 388479)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression - Training and Prediction\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "logistic_model = LogisticRegression(max_iter=1000)\n",
        "logistic_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred_logistic = logistic_model.predict(X_test)\n",
        "accuracy_logistic = accuracy_score(y_test, y_pred_logistic)\n",
        "\n",
        "print(f'Logistic Regression Accuracy: {accuracy_logistic}')\n",
        "print('Classification Report:')\n",
        "print(classification_report(y_test, y_pred_logistic))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hv_qI2VwNj0v",
        "outputId": "2b61a766-8cd1-494e-df63-e9b8138fe474"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy: 0.77919375\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.76      0.77    159494\n",
            "           1       0.77      0.80      0.78    160506\n",
            "\n",
            "    accuracy                           0.78    320000\n",
            "   macro avg       0.78      0.78      0.78    320000\n",
            "weighted avg       0.78      0.78      0.78    320000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Support Vector Machine (SVM) - Training and Prediction\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "svm_model = SVC(kernel='linear')\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred_svm = svm_model.predict(X_test)\n",
        "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
        "\n",
        "print(f'SVM Accuracy: {accuracy_svm}')\n",
        "print('Classification Report:')\n",
        "print(classification_report(y_test, y_pred_svm))"
      ],
      "metadata": {
        "id": "Yn6rdin6OcUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Naives Bayes - Training and Prediction\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "nb_model = MultinomialNB()\n",
        "nb_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred_nb = nb_model.predict(X_test)\n",
        "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
        "\n",
        "print(f'Naive Bayes Accuracy: {accuracy_nb}')\n",
        "print('Classification Report:')\n",
        "print(classification_report(y_test, y_pred_nb))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCJ7ml09PlPj",
        "outputId": "25adf4b7-6e54-4f77-e0dd-801c6a136997"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Accuracy: 0.7589\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.78      0.76    159494\n",
            "           1       0.77      0.74      0.76    160506\n",
            "\n",
            "    accuracy                           0.76    320000\n",
            "   macro avg       0.76      0.76      0.76    320000\n",
            "weighted avg       0.76      0.76      0.76    320000\n",
            "\n"
          ]
        }
      ]
    }
  ]
}